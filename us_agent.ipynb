{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95476fb2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from string import Template\n",
    "from model_provider import ModelProvider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24edbe93",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "openai.api_base = os.environ[\"OPENAI_API_BASE\"]\n",
    "openai.api_type = \"openai\"\n",
    "openai.api_version = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da12212",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_CONFIG = {\n",
    "    \"qwen-plus\": {\"model_id\" : \"qwen-plus\"},\n",
    "    \"qwen2.5-72b\": {\"model_id\" : \"qwen2.5-72b-instruct\"},\n",
    "    \"qwen2.5-32b\": {\"model_id\": \"qwen2.5-32b-instruct\"},\n",
    "    \"qwen2.5-14b\": {\"model_id\": \"qwen2.5-14b-instruct\"},\n",
    "    \"qwen2.5-1.5b\": {\"model_id\": \"qwen2.5-1.5b-instruct\"},\n",
    "    \"deepseekV3\": {\"model_id\" : \"deepseek-v3\"},\n",
    "    \"glm-4.5\": {\"provider\": \"zhipu\", \"model_id\": \"glm-4.5\"}\n",
    "}\n",
    "\n",
    "criteria_config = {\n",
    "    \"well-formed\": lambda story, ac: story,\n",
    "    \"atomic\": lambda story, ac: story,\n",
    "    \"minimal\": lambda story, ac: story,\n",
    "    \"problem-oriented\": lambda story, ac: story, \n",
    "    \"internal-consistency\": lambda story, ac: story,\n",
    "    # é»˜è®¤æƒ…å†µï¼šstory + ac\n",
    "    \"_default\": lambda story, ac: f\"{story}\\n\\n{ac}\"\n",
    "}\n",
    "\n",
    "def build_user_content(criteria: str, story: str, ac: str) -> str:\n",
    "    \"\"\"æ ¹æ®criteriaé€‰æ‹©åˆé€‚çš„user contentç”Ÿæˆè§„åˆ™\"\"\"\n",
    "    func = criteria_config.get(criteria, criteria_config[\"_default\"])\n",
    "    return func(story, ac)\n",
    "\n",
    "def get_model_config(model_name: str):\n",
    "    if model_name not in MODEL_CONFIG:\n",
    "        raise ValueError(f\"Unknown Model: {model_name}\")\n",
    "    cfg = MODEL_CONFIG[model_name]\n",
    "    return {\"provider\": cfg.get(\"provider\", \"openai\"), \"model_id\": cfg[\"model_id\"]}\n",
    "\n",
    "model_list = [\"qwen-plus\",\"qwen2.5-72b\", \"qwen2.5-32b\", \"qwen2.5-14b\", \"qwen2.5-1.5b\", \"deepseekV3\", \"glm-4.5\"]\n",
    "prompt_type_list = [\"zeroshot\", \"fewshot\", \"fewshot-exp\"]\n",
    "criteria_list = [\n",
    "    \"well-formed\", \"atomic\", \"minimal\", \n",
    "    \"unambiguous\", \"conceptually-sound\", \n",
    "    \"problem-oriented\", \"internal-consistency\"\n",
    "]\n",
    "\n",
    "model_name = model_list[6]\n",
    "model = get_model_config(model_name)[\"model_id\"]\n",
    "provider = get_model_config(model_name)[\"provider\"]\n",
    "\n",
    "prompt_type = prompt_type_list[0]\n",
    "criteria = criteria_list[0]\n",
    "provider_client = ModelProvider()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b57ee6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def load_from_file(path: str) -> str:\n",
    "    try:\n",
    "        # è¯»å–æ¨¡æ¿æ–‡ä»¶\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "            return file.read().strip()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"âŒ é”™è¯¯ï¼šæ–‡ä»¶ {path} æœªæ‰¾åˆ°\")\n",
    "        return \"\"\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ é”™è¯¯è¯»å–æ–‡ä»¶ï¼š{e}\")\n",
    "        return \"\"\n",
    "    \n",
    "def clean_json_text(text: str) -> str:\n",
    "    # ç§»é™¤ markdown ä»£ç å—æ ‡è®°\n",
    "    return re.sub(r\"^```(json)?|```$\", \"\", text.strip(), flags=re.IGNORECASE)\n",
    "\n",
    "def evaluate_user_story(system_prompt, user_content: str, provider_client: ModelProvider) -> dict:\n",
    "    try:\n",
    "        content = provider_client.chat_completion(\n",
    "            model=model,\n",
    "            system_prompt=system_prompt,\n",
    "            user_content=user_content,\n",
    "            provider=provider,\n",
    "            temperature=0\n",
    "        )\n",
    "        #print(\"ğŸ§¾ æ¨¡å‹åŸå§‹è¾“å‡ºï¼š\", content)\n",
    "        cleaned = clean_json_text(content)\n",
    "\n",
    "        parsed = json.loads(cleaned)\n",
    "        return parsed\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"âŒ æ¨¡å‹è¿”å›å†…å®¹ä¸æ˜¯æœ‰æ•ˆçš„ JSONï¼š\")\n",
    "        print(content)\n",
    "        print(\"é”™è¯¯ä¿¡æ¯ï¼š\", e)\n",
    "        return {\"error\": \"Invalid JSON\", \"raw\": content}\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ è¯„ä¼°å‡ºé”™ï¼š{e}\")\n",
    "        return {\"error\": str(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b97f01d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "template = load_from_file(\"./prompt/template\")\n",
    "prompt_template = Template(template)\n",
    "quality_criteria = load_from_file(f\"./prompt/{criteria}/{prompt_type}\")\n",
    "prompt = prompt_template.substitute(quality_criteria=quality_criteria)\n",
    "if not prompt:\n",
    "    print(\"âŒ Prompt åŠ è½½å¤±è´¥ï¼Œé€€å‡ºç¨‹åº\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab24f8f8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# === è¯»å–å…¨é‡ç”¨æˆ·æ•…äº‹æ•°æ® ===\n",
    "criteria_col = criteria.capitalize()\n",
    "us_df = pd.read_excel(\"./data/stories.xlsx\", usecols=[\"Issue key\", \"story\", \"ac\", \"bg\", criteria_col])\n",
    "\n",
    "atomic_df = pd.read_excel(f\"data/labeled/{criteria}.xlsx\", usecols=[\"Issue key\"])\n",
    "df_eval = atomic_df.merge(us_df, on=\"Issue key\", how=\"left\")\n",
    "\n",
    "missing = df_eval[df_eval[\"story\"].isnull()]\n",
    "if not missing.empty:\n",
    "    print(\"âš ï¸ ä»¥ä¸‹ Issue key æœªåœ¨ stories.xlsx ä¸­æ‰¾åˆ°ï¼š\")\n",
    "    print(missing[\"Issue key\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf3d5e8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for _, row in tqdm(df_eval.iterrows(), total=len(df_eval), desc=\"Evaluating user stories\"):\n",
    "    issue_key = row[\"Issue key\"]\n",
    "    story = row[\"story\"]\n",
    "    ac = row[\"ac\"]\n",
    "    bg = row[\"bg\"]\n",
    "    expert = row[criteria_col]\n",
    "\n",
    "    if pd.isna(story):\n",
    "        result = {\"error\": \"No story found\"}\n",
    "    else:\n",
    "        user_content = build_user_content(criteria, story, ac)\n",
    "        result = evaluate_user_story(prompt, user_content, provider_client)\n",
    "        time.sleep(1)  # æ¯æ¬¡è°ƒç”¨åæš‚åœ 1 ç§’\n",
    "        agent = -1 # ï¼ˆé»˜è®¤ä¸º -1 è¡¨ç¤ºè§£æå¤±è´¥ï¼‰\n",
    "        if isinstance(result, dict):\n",
    "            v = result.get(f\"violation\")\n",
    "            if v is not None:\n",
    "                agent = 0 if v else 1\n",
    "\n",
    "    results.append({\n",
    "        \"Issue key\": issue_key,\n",
    "        \"Expert\": expert,\n",
    "        \"Agent\": agent,\n",
    "        \"Result\": json.dumps(result, indent=2, ensure_ascii=False)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81f4078",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ç”Ÿæˆå½“å‰æ—¶é—´å­—ç¬¦ä¸²ï¼ˆåˆ°åˆ†é’Ÿï¼‰\n",
    "current_time = datetime.now().strftime(\"%Y%m%d%H%M\")\n",
    "output_file = f\"output/{criteria}-{model_name}-{prompt_type}-{current_time}.xlsx\"\n",
    "pd.DataFrame(results).to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"\\nâœ… ç»“æœå·²ä¿å­˜è‡³ï¼š{output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fcc36e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# === æŒ‡æ ‡è®¡ç®— ===\n",
    "def compute_metrics(df):\n",
    "    df = df[(df[\"Expert\"].isin([0, 1])) & (df[\"Agent\"].isin([0, 1]))]\n",
    "\n",
    "    TP = ((df[\"Expert\"] == 1) & (df[\"Agent\"] == 1)).sum()\n",
    "    TN = ((df[\"Expert\"] == 0) & (df[\"Agent\"] == 0)).sum()\n",
    "    FP = ((df[\"Expert\"] == 0) & (df[\"Agent\"] == 1)).sum()\n",
    "    FN = ((df[\"Expert\"] == 1) & (df[\"Agent\"] == 0)).sum()\n",
    "\n",
    "    total = TP + TN + FP + FN\n",
    "    accuracy = (TP + TN) / total if total else 0\n",
    "    precision = TP / (TP + FP) if (TP + FP) else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) else 0\n",
    "    f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) else 0\n",
    "\n",
    "    print(\"\\nğŸ“Š è¯„ä¼°æŒ‡æ ‡ï¼š\")\n",
    "    print(f\"TP (True Positive): {TP}\")\n",
    "    print(f\"FP (False Positive): {FP}\")\n",
    "    print(f\"TN (True Negative): {TN}\")\n",
    "    print(f\"FN (False Negative): {FN}\")\n",
    "    print(f\"Accuracy å‡†ç¡®ç‡: {accuracy:.4f}\")\n",
    "    print(f\"Precision ç²¾ç¡®ç‡: {precision:.4f}\")\n",
    "    print(f\"Recall å¬å›ç‡: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# === è®¡ç®—Kappaç³»æ•°\n",
    "def compute_cohen_kappa(results_df):\n",
    "    \"\"\"æ ¹æ® DataFrame ä¸­çš„ Expert ä¸ Agent åˆ—ï¼Œè®¡ç®— Cohen's Kappa ç³»æ•°\"\"\"\n",
    "    if \"Expert\" not in results_df.columns or \"Agent\" not in results_df.columns:\n",
    "        print(\"âŒ ç¼ºå°‘ Expert æˆ– Agent åˆ—ï¼Œæ— æ³•è®¡ç®— Kappa\")\n",
    "        return\n",
    "    \n",
    "    # ç§»é™¤æ— æ•ˆï¼ˆ-1ï¼‰çš„ agent å€¼\n",
    "    filtered = results_df[results_df[\"Agent\"] != -1]\n",
    "\n",
    "    if filtered.empty:\n",
    "        print(\"âš ï¸ æ— æœ‰æ•ˆæ¨¡å‹è¯„ä¼°ç»“æœï¼Œè·³è¿‡ Kappa è®¡ç®—\")\n",
    "        return\n",
    "\n",
    "    y_true = filtered[\"Expert\"].astype(int)\n",
    "    y_pred = filtered[\"Agent\"].astype(int)\n",
    "\n",
    "    kappa = cohen_kappa_score(y_true, y_pred)\n",
    "    print(f\"ğŸ“Š Cohen's Kappa ç³»æ•°ï¼š{kappa:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e69e18e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame(results)\n",
    "compute_cohen_kappa(df_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e976ac97",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "compute_metrics(df_result)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
